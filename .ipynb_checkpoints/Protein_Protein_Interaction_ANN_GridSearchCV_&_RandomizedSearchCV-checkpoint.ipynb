{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta_to_df(file_path, content_alias, id_alias = \"ProtID\"):\n",
    "    from Bio import SeqIO\n",
    "    import pandas as pd\n",
    "    with open(file_path) as fasta_file:\n",
    "        ids = []\n",
    "        contents = []\n",
    "        for record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "            ids.append(record.id)\n",
    "            contents.append(record.seq)\n",
    "        df = pd.DataFrame(data = {id_alias: ids, content_alias: contents})\n",
    "        return df.set_index(id_alias)\n",
    "    \n",
    "def filter_unique_rownames(df):\n",
    "    return df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "def import_protvec(filepath, namescol = \"words\"):\n",
    "    \"\"\"\n",
    "    Import data frame of ProtVec 3-grams. \n",
    "    \n",
    "    :param filepath: path to a TSV.\n",
    "    :param namescol: name of a column with row names \n",
    "    :return: pandas dataframe with 3-grams as rownames.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    protvec_df = pd.read_csv(filepath, sep = \"\\t\", header = 0)\n",
    "    protvec_df_3gramidx = protvec_df.set_index(namescol)\n",
    "    return(protvec_df_3gramidx)\n",
    "\n",
    "def get3gramvec(threegr_df, threegr_name, as_list = False):\n",
    "    if not threegr_name in threegr_df.index:\n",
    "        raise ValueError(''.join([\"The supplied ProtVec dataset is not trained for the threegram: \", threegr_name]))\n",
    "    vec = threegr_df.loc[threegr_name].values\n",
    "    if (as_list):\n",
    "        vec = vec.tolist()\n",
    "    return vec\n",
    "    \n",
    "def convert_seq_to_protvec(seq, threegr_df, substitute_any_with=\"G\"):\n",
    "    \"\"\"\n",
    "    Get ProtVec representation of a given sequence\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    protvec = np.zeros(100)\n",
    "    for i in range(0, len(seq) - 3):\n",
    "        this3gram = str(seq[i:i+3])\n",
    "        this3gram = this3gram.replace(\"X\", substitute_any_with)\n",
    "        if not this3gram in threegr_df.index:\n",
    "            # skip untrained 3grams\n",
    "            continue\n",
    "        this3gramvec = get3gramvec(threegr_df, this3gram)\n",
    "\n",
    "        protvec = np.add(protvec, this3gramvec)\n",
    "    # Exploratory DATA Analysis (EDA)\n",
    "    # amino acid sequence length\n",
    "    protvec = np.append(protvec, get_sequence_len(seq))\n",
    "    # add amino acid frequency\n",
    "    \n",
    "    # avg distance between amino\n",
    "    \n",
    "    \n",
    "    return protvec\n",
    "\n",
    "def get_sequence_len(seq):\n",
    "    count = 0\n",
    "    for char in seq:\n",
    "        count+=1\n",
    "    return count\n",
    "\n",
    "def calculate_avg_score(scores):\n",
    "    sum = 0\n",
    "    for value in scores:\n",
    "        sum += value\n",
    "    avg_sum = sum / len(scores)\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "h6hxBmgLdyAI",
    "outputId": "606e8c69-0751-470d-f9e2-98f0256be860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bind/non-bind ratio is 0.6884328358208955\n",
      "1    536\n",
      "0    369\n",
      "Name: Binds, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/universal/anaconda3/lib/python3.6/site-packages/Bio/Seq.py:163: BiopythonWarning: Biopython Seq objects now use string comparison. Older versions of Biopython used object comparison. During this transition, please use hash(id(my_seq)) or my_dict[id(my_seq)] if you want the old behaviour, or use hash(str(my_seq)) or my_dict[str(my_seq)] for the new string hashing behaviour.\n",
      "  \"the new string hashing behaviour.\", BiopythonWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# get current dir/filename\n",
    "import inspect\n",
    "this_file_path = os.path.abspath(inspect.getframeinfo(inspect.currentframe()).filename)\n",
    "this_dir = os.path.dirname(this_file_path)\n",
    "\n",
    "class_path = os.path.join(this_dir, \"data\", \"PP_step1_trn.class\")\n",
    "seq_path = os.path.join(this_dir, \"data\", \"PP_step1_trn.fas\")\n",
    "protvec_file = os.path.join(this_dir, \"data\", \"protVec_100d_3grams.csv\")\n",
    "\n",
    "# parse information\n",
    "class_df = filter_unique_rownames(parse_fasta_to_df(class_path,\"Binds\"))\n",
    "seq_df = filter_unique_rownames(parse_fasta_to_df(seq_path,\"Sequence\"))\n",
    "\n",
    "# Convert levels to numeric\n",
    "class_df['Binds'] = class_df['Binds'].map({\"Bind\" : 1, \"Non_Bind\" : 0})\n",
    "\n",
    "\n",
    "# Get Bind/non-bind ratio\n",
    "counts = class_df['Binds'].value_counts()\n",
    "ratio = counts[0]/counts[1] # 1: 536, # 0: 369\n",
    "print(\"Bind/non-bind ratio is\", str(ratio))\n",
    "print(class_df['Binds'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_H15mko-h6X1"
   },
   "outputs": [],
   "source": [
    "# Convert sequences to their ProtVec representation\n",
    "pv_df = import_protvec(protvec_file)\n",
    "seq_df['Sequence'] = seq_df['Sequence'].apply(convert_seq_to_protvec, args = (pv_df,))\n",
    "\n",
    "# Merge two dataframes into one - REDUNDANT\n",
    "protvec_and_target_df = pd.merge(class_df, seq_df, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO (?): access individual columns from the df\n",
    "protvec_columns_df = pd.DataFrame(protvec_and_target_df['Sequence'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_15D0LoNiFJZ"
   },
   "outputs": [],
   "source": [
    "# Merge two dataframes into one\n",
    "protvec_and_target_df = pd.merge(class_df, seq_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "badZYtTjiGfB"
   },
   "outputs": [],
   "source": [
    "# Eject features and targets, make CV splits\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "N_SPLITS_CV = 5\n",
    "\n",
    "#features = np.stack(protvec_and_target_df['Sequence'].values.tolist(), axis = 0)\n",
    "features = np.stack(protvec_and_target_df['Sequence'].values.tolist(), axis = 0)\n",
    "targets = protvec_and_target_df['Binds'].values # == labels\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS_CV)\n",
    "folds = skf.split(features, targets)\n",
    "\n",
    "for train_index, test_index in folds:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]# test layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JDT6HDyuiGtk",
    "outputId": "9775e5b5-5633-4f22-a156-c78385e573c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64285714 0.63535912 0.63535912 0.67955801 0.68333333]\n",
      "0.6552933438568799\n"
     ]
    }
   ],
   "source": [
    "##### Fit ANN # http://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(6, 279), random_state=1)\n",
    "#clf = MLPClassifier(warm_start= True, verbose= True, tol= 0.001, solver= 'lbfgs', \n",
    "#                    random_state = 6, max_iter = 100, \n",
    "#                    learning_rate_init = 0.83854545454545459, learning_rate = 'invscaling',\n",
    "#                    hidden_layer_sizes = 24001, batch_size = 'auto', \n",
    "#                    alpha = 0.28283545454545456, activation = 'logistic')\n",
    "clf.fit(X, y)    \n",
    "\n",
    "# Predict sample\n",
    "clf.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(clf, features, targets, cv = skf)\n",
    "print(scores)\n",
    "score_sum = 0\n",
    "for score in scores:\n",
    "    score_sum += score\n",
    "score_avg = score_sum / len(scores)\n",
    "print(score_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape:  (725, 101)\n",
      "Testing features shape:  (180, 101)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training features shape: \", X_train.shape)\n",
    "print(\"Testing features shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# hidden layers: generates list of n_max tuples with \n",
    "# length: n_l_min--n_l_max integers, value: each between n_a_min and n_a_max\n",
    "# https://www.kaggle.com/jilkoval/titanic-with-random-forest-and-neural-networks\n",
    "def rand_hidden_layer_sizes(n_l_min,n_l_max,n_a_min,n_a_max,n_max=1000):\n",
    "    n_l = np.random.randint(n_l_min,n_l_max,n_max)\n",
    "    list_hl = []\n",
    "    for nl_i in n_l:\n",
    "        list_hl.append(tuple(np.random.randint(n_a_min,n_a_max,nl_i)))\n",
    "    return list_hl\n",
    "\n",
    "hidden_layers = rand_hidden_layer_sizes(1,3,1,10000,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter space to search\n",
    "# solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(6, 279), random_state=1\n",
    "parameter_space = {\n",
    "'hidden_layer_sizes': list(range(5000, 30000)) # https://stackoverflow.com/a/52029734\n",
    ",'activation' : ['relu', 'identity', 'logistic', 'tanh'] #'\n",
    ",'solver': ['lbfgs'] # lbfgs performs well on small datasets\n",
    ",'alpha': list(np.linspace(0.00001, 1, 100))\n",
    ",'batch_size' : ['auto'] # not used when solver is lbfgs\n",
    ",'learning_rate' : ['constant','invscaling','adaptive'] # only with solver l\n",
    ",'learning_rate_init' : list(np.linspace(0.001, 1, 100))\n",
    ",'max_iter' : [50, 100, 150, 300, 600]\n",
    ",'random_state' : [6] # sets the seed\n",
    ",'warm_start' : [False, True]\n",
    ",'tol' : [0.0001, 0.001, 0.01, 0.1, 1]\n",
    ",'verbose' : [True] # prints progress to stdout\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# parameters not used\n",
    "# ,'power_t' : [0.5, ] # only when solver is SGD\n",
    "# #'early_stopping' : [False], # only with SGD or ADAM\n",
    "#'beta_1' : [0.9], # not with LBFGS\n",
    "#'beta_2' : [0.999], # not with LBFGS\n",
    "#'epsilon' : [1e-8] # not with LBFGS\n",
    "#,'n_iter_no_change' : [10] # not with LBFGS\n",
    "#'nesterovs_momentum' : [True], # only with SGD\n",
    "#'momentum' : [0.9], # only with SGD\n",
    "#'shuffle' : [True], # only with SGD or ADAM\n",
    "#'validation_fraction' : [0.1] # not with LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'warm_start': True, 'verbose': True, 'tol': 0.001, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 100, 'learning_rate_init': 0.83854545454545459, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 24001, 'batch_size': 'auto', 'alpha': 0.28283545454545456, 'activation': 'logistic'}\n",
      "0.680 (+/-0.016) for {'warm_start': True, 'verbose': True, 'tol': 0.001, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 50, 'learning_rate_init': 0.30372727272727273, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 20395, 'batch_size': 'auto', 'alpha': 0.16162454545454547, 'activation': 'logistic'}\n",
      "0.499 (+/-0.046) for {'warm_start': True, 'verbose': True, 'tol': 0.1, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 300, 'learning_rate_init': 0.27345454545454545, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 14399, 'batch_size': 'auto', 'alpha': 0.19192727272727272, 'activation': 'logistic'}\n",
      "0.647 (+/-0.017) for {'warm_start': False, 'verbose': True, 'tol': 0.0001, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 600, 'learning_rate_init': 0.3642727272727273, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 29390, 'batch_size': 'auto', 'alpha': 0.47475272727272727, 'activation': 'identity'}\n",
      "0.668 (+/-0.042) for {'warm_start': False, 'verbose': True, 'tol': 0.01, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 100, 'learning_rate_init': 0.76790909090909099, 'learning_rate': 'constant', 'hidden_layer_sizes': 23203, 'batch_size': 'auto', 'alpha': 0.44445000000000001, 'activation': 'tanh'}\n",
      "0.657 (+/-0.036) for {'warm_start': True, 'verbose': True, 'tol': 0.0001, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 300, 'learning_rate_init': 0.5459090909090909, 'learning_rate': 'constant', 'hidden_layer_sizes': 15820, 'batch_size': 'auto', 'alpha': 0.56566090909090905, 'activation': 'logistic'}\n",
      "0.586 (+/-0.012) for {'warm_start': True, 'verbose': True, 'tol': 1, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 100, 'learning_rate_init': 0.27345454545454545, 'learning_rate': 'constant', 'hidden_layer_sizes': 17568, 'batch_size': 'auto', 'alpha': 0.82828454545454544, 'activation': 'relu'}\n",
      "0.636 (+/-0.026) for {'warm_start': True, 'verbose': True, 'tol': 0.1, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 50, 'learning_rate_init': 0.061545454545454549, 'learning_rate': 'constant', 'hidden_layer_sizes': 26116, 'batch_size': 'auto', 'alpha': 0.69697272727272719, 'activation': 'tanh'}\n",
      "0.702 (+/-0.041) for {'warm_start': True, 'verbose': True, 'tol': 0.001, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 100, 'learning_rate_init': 0.83854545454545459, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 24001, 'batch_size': 'auto', 'alpha': 0.28283545454545456, 'activation': 'logistic'}\n",
      "0.621 (+/-0.024) for {'warm_start': True, 'verbose': True, 'tol': 0.0001, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 150, 'learning_rate_init': 0.38445454545454549, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 6809, 'batch_size': 'auto', 'alpha': 0.45455090909090912, 'activation': 'identity'}\n",
      "0.630 (+/-0.009) for {'warm_start': True, 'verbose': True, 'tol': 0.001, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 300, 'learning_rate_init': 0.64681818181818185, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 12898, 'batch_size': 'auto', 'alpha': 0.83838545454545454, 'activation': 'identity'}\n"
     ]
    }
   ],
   "source": [
    "# first randomized search to find roughly the best attributes\n",
    "# choosing classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=150) # max_iter will be constant\n",
    "\n",
    "# running the search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(mlp, parameter_space, cv=3, scoring='accuracy')\n",
    "random_search.fit(X, y)\n",
    "\n",
    "\n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', random_search.best_params_)\n",
    "\n",
    "# All results\n",
    "means = random_search.cv_results_['mean_test_score']\n",
    "stds = random_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, random_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b6b6e60d91bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mhidden_layer_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     alpha = 0.28283545454545456, activation = 'logistic')\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Predict sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \"\"\"\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0;32m--> 382\u001b[0;31m                             intercept_grads, layer_units)\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0miprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mpgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[0;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0;32m--> 178\u001b[0;31m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Get loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 104\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# best scores so far with RandomizedSearchCV, without EDA:\n",
    "# 0.687 (+/-0.024) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 6, 'power_t': 0.5, 'max_iter': 50, 'learning_rate_init': 0.80827272727272736, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 8585, 'batch_size': 'auto', 'alpha': 0.19192727272727272, 'activation': 'logistic'}\n",
    "# 0.683 (+/-0.028) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 6, 'power_t': 0.5, 'max_iter': 50, 'learning_rate_init': 0.8183636363636364, 'learning_rate': 'constant', 'hidden_layer_sizes': 9900, 'batch_size': 'auto', 'alpha': 0.92929363636363627, 'activation': 'logistic'}\n",
    "# 0.672 (+/-0.031) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 6, 'power_t': 0.5, 'max_iter': 150, 'learning_rate_init': 0.17254545454545456, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 7369, 'batch_size': 'auto', 'alpha': 0.29293636363636366, 'activation': 'logistic'}\n",
    "# 0.665 (+/-0.034) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 6, 'power_t': 0.5, 'max_iter': 50, 'learning_rate_init': 0.27345454545454545, 'learning_rate': 'constant', 'hidden_layer_sizes': 1800, 'batch_size': 'auto', 'alpha': 0.001, 'activation': 'logistic'}\n",
    "# 0.663 (+/-0.024) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 6, 'power_t': 0.5, 'max_iter': 150, 'learning_rate_init': 0.63672727272727281, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (4115,), 'batch_size': 'auto', 'alpha': 1e-05, 'activation': 'logistic'}\n",
    "# 0.652 (+/-0.090) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 6, 'power_t': 0.5, 'max_iter': 100, 'learning_rate_init': 0.16245454545454546, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (17, 16, 14, 5, 19, 14, 15, 13, 14, 9, 11, 11), 'batch_size': 'auto', 'alpha': 1e-05, 'activation': 'identity'}\n",
    "# 0.650 (+/-0.036) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 6, 'power_t': 0.5, 'max_iter': 50, 'learning_rate_init': 0.33400000000000002, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (97, 14, 30, 59), 'batch_size': 'auto', 'alpha': 0.0001, 'activation': 'identity'}\n",
    "# 0.650 (+/-0.025) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 6, 'power_t': 0.5, 'max_iter': 150, 'learning_rate_init': 0.62663636363636366, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (27, 58, 30), 'batch_size': 'auto', 'alpha': 0.0001, 'activation': 'relu'}\n",
    "# 0.646 (+/-0.022) for {'verbose': True, 'solver': 'lbfgs', 'random_state': 4, 'power_t': 0.5, 'max_iter': 50, 'learning_rate_init': 0.7477272727272728, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 700, 'batch_size': 'auto', 'alpha': 0.001, 'activation': 'relu'}\n",
    "\n",
    "# parameters with EDA length\n",
    "# 0.702 (+/-0.041) for {'warm_start': True, 'verbose': True, 'tol': 0.001, 'solver': 'lbfgs', 'random_state': 6, 'max_iter': 100, 'learning_rate_init': 0.83854545454545459, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 24001, 'batch_size': 'auto', 'alpha': 0.28283545454545456, 'activation': 'logistic'}\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "\n",
    "clf = MLPClassifier(warm_start= True, verbose= True, tol= 0.001, solver= 'lbfgs', \n",
    "                    random_state = 6, max_iter = 100, \n",
    "                    learning_rate_init = 0.83854545454545459, learning_rate = 'invscaling',\n",
    "                    hidden_layer_sizes = 24001, batch_size = 'auto', \n",
    "                    alpha = 0.28283545454545456, activation = 'logistic')\n",
    "clf.fit(X, y)    \n",
    "\n",
    "# Predict sample\n",
    "clf.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(clf, features, targets, cv = skf)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for GridSearchCV\n",
    "parameter_space = { \n",
    "    'verbose' : [True], \n",
    "    'solver' : ['lbfgs'],\n",
    "    'random_state' : [4,6], \n",
    "    'power_t' : [0.5], \n",
    "    'max_iter' : [50, 100, 150], \n",
    "    'learning_rate_init' :  [0.83854545454545459, 0.7477272727272728, 0.62663636363636366, 0.33400000000000002, \n",
    "                         0.16245454545454546, 0.63672727272727281, 0.27345454545454545, 0.17254545454545456, \n",
    "                         0.8183636363636364, 0.80827272727272736], \n",
    "    'learning_rate' : ['adaptive', 'constant', 'invscaling'], \n",
    "    'hidden_layer_sizes' : [8585, 9900, 7369, 1800, 4415, (17, 16, 14, 5, 19, 14, 15, 13, 14, 9, 11, 11), \n",
    "                                           (97, 14, 30, 59), (27, 58, 30), 700, 24001], \n",
    "    'batch_size' : ['auto'], \n",
    "    'alpha' : [0.19192727272727272, 0.92929363636363627, 0.29293636363636366, 0.001,\n",
    "                                                             1e-05, 1e-05, 0.0001, 0.28283545454545456], \n",
    "    'activation' : ['logistic', 'identity', 'relu']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing GridSearchCV with the best results that I got from RandomizedSearchCV\n",
    "# choosing classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=3)\n",
    "\n",
    "# running the search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "random_search = GridSearchCV(mlp, parameter_space, cv=3, scoring='accuracy')\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# \n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', random_search.best_params_)\n",
    "\n",
    "# All results\n",
    "means = random_search.cv_results_['mean_test_score']\n",
    "stds = random_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, random_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing GridSearchCV in the parameter spaces close the best parameters so far"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Protein-Protein Interaction - ANN - GridSearchCV & RandomizedSearchCV.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
